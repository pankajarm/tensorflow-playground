{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import usual suspects\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Get Data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup hyper Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 20\n",
    "batch_size = 128\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph setup placeholders inputs (no need to set them as variable)\n",
    "\n",
    "# mnist input data image are shape of 28*28 = 784 \n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "# mnist output label is from 0 to 9, so Total 10 classes\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph setup variable weight and variable bias, because back propogatin will change it\n",
    "\n",
    "W = tf.Variable(tf.zeros([784, 10]) , name='weight')\n",
    "b = tf.Variable(tf.zeros([10]) , name='bias')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct the logistic Regression model\n",
    "pred = tf.nn.softmax(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize errors using cross entroy\n",
    "# mean of sum of -ylog(y^)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(pred) , axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use a Gradient Descent optimizer\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing the weight\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch= 1 Cost= 0.528178\n",
      "Epoch= 2 Cost= 0.611842\n",
      "Epoch= 3 Cost= 0.605107\n",
      "Epoch= 4 Cost= 0.447424\n",
      "Epoch= 5 Cost= 0.619405\n",
      "Epoch= 6 Cost= 0.563341\n",
      "Epoch= 7 Cost= 0.426615\n",
      "Epoch= 8 Cost= 0.358067\n",
      "Epoch= 9 Cost= 0.420005\n",
      "Epoch= 10 Cost= 0.397361\n",
      "Epoch= 11 Cost= 0.410622\n",
      "Epoch= 12 Cost= 0.415332\n",
      "Epoch= 13 Cost= 0.389243\n",
      "Epoch= 14 Cost= 0.358025\n",
      "Epoch= 15 Cost= 0.331358\n",
      "Epoch= 16 Cost= 0.277273\n",
      "Epoch= 17 Cost= 0.335919\n",
      "Epoch= 18 Cost= 0.333279\n",
      "Epoch= 19 Cost= 0.293978\n",
      "Epoch= 20 Cost= 0.296054\n",
      "Optimization Finished\n",
      "Accuracy: 0.9091\n"
     ]
    }
   ],
   "source": [
    "# Launch the Graph withing tf Session\n",
    "with tf.Session() as sess:\n",
    "    #initialize all the variables\n",
    "    sess.run(init)\n",
    "    \n",
    "    # now, let's do the Training Cycle for each epoch\n",
    "    for epoch in range(training_epochs):\n",
    "        # setup avg_cost\n",
    "        avg_cost =0\n",
    "        # get total batch size\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # then loop over all the batches\n",
    "        for batch in range(total_batch):\n",
    "            trainX, trainY = mnist.train.next_batch(batch_size=batch_size)\n",
    "            \n",
    "            # Fit model using trainign data\n",
    "            o,c = sess.run([optimizer, cost], feed_dict={X: trainX, Y:trainY})\n",
    "            \n",
    "            #compute average cost\n",
    "            avg_cost += c/ total_batch\n",
    "            \n",
    "        #display logs each epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print (\"Epoch=\", epoch+1, \"Cost=\", c)\n",
    "            \n",
    "    #when done print optimization finished\n",
    "    print (\"Optimization Finished\")\n",
    "        \n",
    "    #Test Model\n",
    "    correct_predection = tf.equal(tf.argmax(pred, axis=1), tf.argmax(Y, axis=1))\n",
    "        \n",
    "    #calculate accuracy average for correct_predection\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predection, tf.float32))\n",
    "    # evaluate accuracy with test image data and print\n",
    "    print (\"Accuracy:\", accuracy.eval(feed_dict={X:mnist.test.images ,Y:mnist.test.labels}))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
