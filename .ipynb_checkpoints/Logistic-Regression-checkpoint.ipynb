{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import usual suspects\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Get Data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup hyper Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 20\n",
    "batch_size = 128\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph setup placeholders inputs (no need to set them as variable)\n",
    "\n",
    "# mnist input data image are shape of 28*28 = 784 \n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "# mnist output label is from 0 to 9, so Total 10 classes\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph setup variable weight and variable bias, because back propogatin will change it\n",
    "\n",
    "W = tf.Variable(tf.zeros([784, 10]) , name='weight')\n",
    "b = tf.Variable(tf.zeros([10]) , name='bias')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct the logistic Regression model\n",
    "pred = tf.nn.softmax(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Minimize errors using cross entroy\n",
    "# mean of sum of -ylog(y^)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(pred) , axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use a Gradient Descent optimizer\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing the weight\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch= 1 Cost= 0.528178\n",
      "Epoch= 2 Cost= 0.608264\n",
      "Epoch= 3 Cost= 0.597769\n",
      "Epoch= 4 Cost= 0.430276\n",
      "Epoch= 5 Cost= 0.418823\n",
      "Epoch= 6 Cost= 0.416013\n",
      "Epoch= 7 Cost= 0.475231\n",
      "Epoch= 8 Cost= 0.413317\n",
      "Epoch= 9 Cost= 0.488328\n",
      "Epoch= 10 Cost= 0.350499\n",
      "Epoch= 11 Cost= 0.526409\n",
      "Epoch= 12 Cost= 0.414483\n",
      "Epoch= 13 Cost= 0.42285\n",
      "Epoch= 14 Cost= 0.282604\n",
      "Epoch= 15 Cost= 0.297706\n",
      "Epoch= 16 Cost= 0.431901\n",
      "Epoch= 17 Cost= 0.418367\n",
      "Epoch= 18 Cost= 0.391365\n",
      "Epoch= 19 Cost= 0.309326\n",
      "Epoch= 20 Cost= 0.317846\n",
      "Epoch= 21 Cost= 0.320261\n",
      "Epoch= 22 Cost= 0.353118\n",
      "Epoch= 23 Cost= 0.372254\n",
      "Epoch= 24 Cost= 0.350392\n",
      "Epoch= 25 Cost= 0.345359\n",
      "Epoch= 26 Cost= 0.372834\n",
      "Epoch= 27 Cost= 0.403829\n",
      "Epoch= 28 Cost= 0.257368\n",
      "Epoch= 29 Cost= 0.364071\n",
      "Epoch= 30 Cost= 0.355913\n",
      "Epoch= 31 Cost= 0.418538\n",
      "Epoch= 32 Cost= 0.267175\n",
      "Epoch= 33 Cost= 0.361778\n",
      "Epoch= 34 Cost= 0.306371\n",
      "Epoch= 35 Cost= 0.40059\n",
      "Epoch= 36 Cost= 0.476422\n",
      "Epoch= 37 Cost= 0.289388\n",
      "Epoch= 38 Cost= 0.409925\n",
      "Epoch= 39 Cost= 0.309608\n",
      "Epoch= 40 Cost= 0.306753\n",
      "Epoch= 41 Cost= 0.288417\n",
      "Epoch= 42 Cost= 0.262406\n",
      "Epoch= 43 Cost= 0.203343\n",
      "Epoch= 44 Cost= 0.267743\n",
      "Epoch= 45 Cost= 0.371486\n",
      "Epoch= 46 Cost= 0.515096\n",
      "Epoch= 47 Cost= 0.305435\n",
      "Epoch= 48 Cost= 0.269253\n",
      "Epoch= 49 Cost= 0.232068\n",
      "Epoch= 50 Cost= 0.325267\n",
      "Epoch= 51 Cost= 0.48542\n",
      "Epoch= 52 Cost= 0.301304\n",
      "Epoch= 53 Cost= 0.363046\n",
      "Epoch= 54 Cost= 0.334555\n",
      "Epoch= 55 Cost= 0.389457\n",
      "Epoch= 56 Cost= 0.307209\n",
      "Epoch= 57 Cost= 0.344044\n",
      "Epoch= 58 Cost= 0.263671\n",
      "Epoch= 59 Cost= 0.324291\n",
      "Epoch= 60 Cost= 0.213472\n",
      "Optimization Finished\n",
      "Accuracy: 0.918\n"
     ]
    }
   ],
   "source": [
    "# Launch the Graph withing tf Session\n",
    "with tf.Session() as sess:\n",
    "    #initialize all the variables\n",
    "    sess.run(init)\n",
    "    \n",
    "    # now, let's do the Training Cycle for each epoch\n",
    "    for epoch in range(training_epochs):\n",
    "        # setup avg_cost\n",
    "        avg_cost =0\n",
    "        # get total batch size\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # then loop over all the batches\n",
    "        for batch in range(total_batch):\n",
    "            trainX, trainY = mnist.train.next_batch(batch_size=batch_size)\n",
    "            \n",
    "            # Fit model using trainign data\n",
    "            o,c = sess.run([optimizer, cost], feed_dict={X: trainX, Y:trainY})\n",
    "            \n",
    "            #compute average cost\n",
    "            avg_cost += c/ total_batch\n",
    "            \n",
    "        #display logs each epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print (\"Epoch=\", epoch+1, \"Cost=\", c)\n",
    "            \n",
    "    #when done print optimization finished\n",
    "    print (\"Optimization Finished\")\n",
    "        \n",
    "    #Test Model\n",
    "    correct_predection = tf.equal(tf.argmax(pred, axis=1), tf.argmax(Y, axis=1))\n",
    "        \n",
    "    #calculate accuracy average for correct_predection\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predection, tf.float32))\n",
    "    # evaluate accuracy with test image data and print\n",
    "    print (\"Accuracy:\", accuracy.eval(feed_dict={X:mnist.test.images ,Y:mnist.test.labels}))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
